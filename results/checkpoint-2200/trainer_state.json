{
  "best_global_step": 2200,
  "best_metric": 1.538297414779663,
  "best_model_checkpoint": "./results/checkpoint-2200",
  "epoch": 1.4381232630374368,
  "eval_steps": 100,
  "global_step": 2200,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.006539153179663234,
      "grad_norm": 0.4913782775402069,
      "learning_rate": 0.00019960784313725492,
      "loss": 2.5619,
      "step": 10
    },
    {
      "epoch": 0.013078306359326467,
      "grad_norm": 0.5442877411842346,
      "learning_rate": 0.00019917211328976034,
      "loss": 2.2251,
      "step": 20
    },
    {
      "epoch": 0.0196174595389897,
      "grad_norm": 0.578446090221405,
      "learning_rate": 0.0001987363834422658,
      "loss": 2.0744,
      "step": 30
    },
    {
      "epoch": 0.026156612718652935,
      "grad_norm": 0.6296255588531494,
      "learning_rate": 0.00019830065359477126,
      "loss": 1.9758,
      "step": 40
    },
    {
      "epoch": 0.032695765898316166,
      "grad_norm": 0.5983937382698059,
      "learning_rate": 0.0001978649237472767,
      "loss": 1.8696,
      "step": 50
    },
    {
      "epoch": 0.0392349190779794,
      "grad_norm": 0.6146573424339294,
      "learning_rate": 0.00019742919389978213,
      "loss": 1.8707,
      "step": 60
    },
    {
      "epoch": 0.045774072257642635,
      "grad_norm": 0.613584041595459,
      "learning_rate": 0.0001969934640522876,
      "loss": 1.7717,
      "step": 70
    },
    {
      "epoch": 0.05231322543730587,
      "grad_norm": 0.5970416069030762,
      "learning_rate": 0.00019655773420479305,
      "loss": 1.8288,
      "step": 80
    },
    {
      "epoch": 0.058852378616969105,
      "grad_norm": 0.5383694171905518,
      "learning_rate": 0.00019612200435729847,
      "loss": 1.8025,
      "step": 90
    },
    {
      "epoch": 0.06539153179663233,
      "grad_norm": 0.6433767676353455,
      "learning_rate": 0.00019568627450980392,
      "loss": 1.7629,
      "step": 100
    },
    {
      "epoch": 0.06539153179663233,
      "eval_loss": 1.7574068307876587,
      "eval_runtime": 241.7641,
      "eval_samples_per_second": 5.625,
      "eval_steps_per_second": 1.406,
      "step": 100
    },
    {
      "epoch": 0.07193068497629557,
      "grad_norm": 0.6239737272262573,
      "learning_rate": 0.0001952505446623094,
      "loss": 1.7493,
      "step": 110
    },
    {
      "epoch": 0.0784698381559588,
      "grad_norm": 0.53157639503479,
      "learning_rate": 0.00019481481481481482,
      "loss": 1.7574,
      "step": 120
    },
    {
      "epoch": 0.08500899133562204,
      "grad_norm": 0.5737268328666687,
      "learning_rate": 0.00019437908496732027,
      "loss": 1.8207,
      "step": 130
    },
    {
      "epoch": 0.09154814451528527,
      "grad_norm": 0.5999802350997925,
      "learning_rate": 0.0001939433551198257,
      "loss": 1.7633,
      "step": 140
    },
    {
      "epoch": 0.0980872976949485,
      "grad_norm": 0.5366747975349426,
      "learning_rate": 0.00019350762527233116,
      "loss": 1.7354,
      "step": 150
    },
    {
      "epoch": 0.10462645087461174,
      "grad_norm": 0.5774924159049988,
      "learning_rate": 0.0001930718954248366,
      "loss": 1.7707,
      "step": 160
    },
    {
      "epoch": 0.11116560405427497,
      "grad_norm": 0.6881104111671448,
      "learning_rate": 0.00019263616557734206,
      "loss": 1.7146,
      "step": 170
    },
    {
      "epoch": 0.11770475723393821,
      "grad_norm": 0.5057945847511292,
      "learning_rate": 0.0001922004357298475,
      "loss": 1.7444,
      "step": 180
    },
    {
      "epoch": 0.12424391041360144,
      "grad_norm": 0.5438645482063293,
      "learning_rate": 0.00019176470588235295,
      "loss": 1.7739,
      "step": 190
    },
    {
      "epoch": 0.13078306359326466,
      "grad_norm": 0.5441312789916992,
      "learning_rate": 0.0001913289760348584,
      "loss": 1.6803,
      "step": 200
    },
    {
      "epoch": 0.13078306359326466,
      "eval_loss": 1.7057480812072754,
      "eval_runtime": 218.9683,
      "eval_samples_per_second": 6.211,
      "eval_steps_per_second": 1.553,
      "step": 200
    },
    {
      "epoch": 0.1373222167729279,
      "grad_norm": 0.5911046266555786,
      "learning_rate": 0.00019089324618736385,
      "loss": 1.7387,
      "step": 210
    },
    {
      "epoch": 0.14386136995259113,
      "grad_norm": 0.625411868095398,
      "learning_rate": 0.00019045751633986927,
      "loss": 1.7024,
      "step": 220
    },
    {
      "epoch": 0.15040052313225438,
      "grad_norm": 0.5185709595680237,
      "learning_rate": 0.00019002178649237474,
      "loss": 1.7007,
      "step": 230
    },
    {
      "epoch": 0.1569396763119176,
      "grad_norm": 0.5159897804260254,
      "learning_rate": 0.0001895860566448802,
      "loss": 1.7589,
      "step": 240
    },
    {
      "epoch": 0.16347882949158085,
      "grad_norm": 0.6430929899215698,
      "learning_rate": 0.00018915032679738564,
      "loss": 1.6824,
      "step": 250
    },
    {
      "epoch": 0.17001798267124407,
      "grad_norm": 0.5787667632102966,
      "learning_rate": 0.00018871459694989109,
      "loss": 1.6855,
      "step": 260
    },
    {
      "epoch": 0.17655713585090732,
      "grad_norm": 0.5445156097412109,
      "learning_rate": 0.00018827886710239653,
      "loss": 1.6812,
      "step": 270
    },
    {
      "epoch": 0.18309628903057054,
      "grad_norm": 0.5754090547561646,
      "learning_rate": 0.00018784313725490198,
      "loss": 1.7182,
      "step": 280
    },
    {
      "epoch": 0.18963544221023376,
      "grad_norm": 0.5469880104064941,
      "learning_rate": 0.0001874074074074074,
      "loss": 1.7255,
      "step": 290
    },
    {
      "epoch": 0.196174595389897,
      "grad_norm": 0.4727623462677002,
      "learning_rate": 0.00018697167755991288,
      "loss": 1.8147,
      "step": 300
    },
    {
      "epoch": 0.196174595389897,
      "eval_loss": 1.678889513015747,
      "eval_runtime": 223.6013,
      "eval_samples_per_second": 6.082,
      "eval_steps_per_second": 1.521,
      "step": 300
    },
    {
      "epoch": 0.20271374856956023,
      "grad_norm": 0.5916269421577454,
      "learning_rate": 0.00018653594771241832,
      "loss": 1.7511,
      "step": 310
    },
    {
      "epoch": 0.20925290174922348,
      "grad_norm": 0.5319245457649231,
      "learning_rate": 0.00018610021786492374,
      "loss": 1.7014,
      "step": 320
    },
    {
      "epoch": 0.2157920549288867,
      "grad_norm": 0.5136941075325012,
      "learning_rate": 0.0001856644880174292,
      "loss": 1.6647,
      "step": 330
    },
    {
      "epoch": 0.22233120810854995,
      "grad_norm": 0.5006778240203857,
      "learning_rate": 0.00018522875816993467,
      "loss": 1.7019,
      "step": 340
    },
    {
      "epoch": 0.22887036128821317,
      "grad_norm": 0.5374467372894287,
      "learning_rate": 0.0001847930283224401,
      "loss": 1.7171,
      "step": 350
    },
    {
      "epoch": 0.23540951446787642,
      "grad_norm": 0.636685311794281,
      "learning_rate": 0.00018435729847494553,
      "loss": 1.6309,
      "step": 360
    },
    {
      "epoch": 0.24194866764753964,
      "grad_norm": 0.547869086265564,
      "learning_rate": 0.00018392156862745098,
      "loss": 1.7242,
      "step": 370
    },
    {
      "epoch": 0.2484878208272029,
      "grad_norm": 0.524599015712738,
      "learning_rate": 0.00018348583877995643,
      "loss": 1.7186,
      "step": 380
    },
    {
      "epoch": 0.25502697400686614,
      "grad_norm": 0.6149503588676453,
      "learning_rate": 0.00018305010893246188,
      "loss": 1.6704,
      "step": 390
    },
    {
      "epoch": 0.26156612718652933,
      "grad_norm": 0.5643536448478699,
      "learning_rate": 0.00018261437908496733,
      "loss": 1.6651,
      "step": 400
    },
    {
      "epoch": 0.26156612718652933,
      "eval_loss": 1.658518671989441,
      "eval_runtime": 219.4631,
      "eval_samples_per_second": 6.197,
      "eval_steps_per_second": 1.549,
      "step": 400
    },
    {
      "epoch": 0.2681052803661926,
      "grad_norm": 0.5600723028182983,
      "learning_rate": 0.00018217864923747277,
      "loss": 1.7067,
      "step": 410
    },
    {
      "epoch": 0.2746444335458558,
      "grad_norm": 0.6071316003799438,
      "learning_rate": 0.00018174291938997822,
      "loss": 1.6642,
      "step": 420
    },
    {
      "epoch": 0.281183586725519,
      "grad_norm": 0.6321918368339539,
      "learning_rate": 0.00018130718954248367,
      "loss": 1.6423,
      "step": 430
    },
    {
      "epoch": 0.28772273990518227,
      "grad_norm": 0.5317146182060242,
      "learning_rate": 0.00018087145969498912,
      "loss": 1.6544,
      "step": 440
    },
    {
      "epoch": 0.2942618930848455,
      "grad_norm": 0.6450583338737488,
      "learning_rate": 0.00018043572984749456,
      "loss": 1.6691,
      "step": 450
    },
    {
      "epoch": 0.30080104626450876,
      "grad_norm": 0.6253681182861328,
      "learning_rate": 0.00018,
      "loss": 1.6794,
      "step": 460
    },
    {
      "epoch": 0.30734019944417196,
      "grad_norm": 0.512182354927063,
      "learning_rate": 0.00017956427015250546,
      "loss": 1.6797,
      "step": 470
    },
    {
      "epoch": 0.3138793526238352,
      "grad_norm": 0.5966664552688599,
      "learning_rate": 0.0001791285403050109,
      "loss": 1.6557,
      "step": 480
    },
    {
      "epoch": 0.32041850580349845,
      "grad_norm": 0.5896806716918945,
      "learning_rate": 0.00017869281045751635,
      "loss": 1.7,
      "step": 490
    },
    {
      "epoch": 0.3269576589831617,
      "grad_norm": 0.5711008310317993,
      "learning_rate": 0.0001782570806100218,
      "loss": 1.6351,
      "step": 500
    },
    {
      "epoch": 0.3269576589831617,
      "eval_loss": 1.6435894966125488,
      "eval_runtime": 215.2008,
      "eval_samples_per_second": 6.32,
      "eval_steps_per_second": 1.58,
      "step": 500
    },
    {
      "epoch": 0.3334968121628249,
      "grad_norm": 0.5347259640693665,
      "learning_rate": 0.00017782135076252725,
      "loss": 1.6248,
      "step": 510
    },
    {
      "epoch": 0.34003596534248814,
      "grad_norm": 0.5667480230331421,
      "learning_rate": 0.00017738562091503267,
      "loss": 1.6372,
      "step": 520
    },
    {
      "epoch": 0.3465751185221514,
      "grad_norm": 0.58134526014328,
      "learning_rate": 0.00017694989106753814,
      "loss": 1.6533,
      "step": 530
    },
    {
      "epoch": 0.35311427170181464,
      "grad_norm": 0.560053825378418,
      "learning_rate": 0.0001765141612200436,
      "loss": 1.6769,
      "step": 540
    },
    {
      "epoch": 0.35965342488147783,
      "grad_norm": 0.6323817372322083,
      "learning_rate": 0.000176078431372549,
      "loss": 1.6435,
      "step": 550
    },
    {
      "epoch": 0.3661925780611411,
      "grad_norm": 0.5822235941886902,
      "learning_rate": 0.00017564270152505446,
      "loss": 1.6301,
      "step": 560
    },
    {
      "epoch": 0.37273173124080433,
      "grad_norm": 0.5685442090034485,
      "learning_rate": 0.00017520697167755994,
      "loss": 1.6745,
      "step": 570
    },
    {
      "epoch": 0.3792708844204675,
      "grad_norm": 0.5682258009910583,
      "learning_rate": 0.00017477124183006536,
      "loss": 1.6617,
      "step": 580
    },
    {
      "epoch": 0.3858100376001308,
      "grad_norm": 0.6614441871643066,
      "learning_rate": 0.0001743355119825708,
      "loss": 1.5535,
      "step": 590
    },
    {
      "epoch": 0.392349190779794,
      "grad_norm": 0.5407148599624634,
      "learning_rate": 0.00017389978213507625,
      "loss": 1.6558,
      "step": 600
    },
    {
      "epoch": 0.392349190779794,
      "eval_loss": 1.6315984725952148,
      "eval_runtime": 214.0346,
      "eval_samples_per_second": 6.354,
      "eval_steps_per_second": 1.589,
      "step": 600
    },
    {
      "epoch": 0.39888834395945727,
      "grad_norm": 0.5632877945899963,
      "learning_rate": 0.00017346405228758173,
      "loss": 1.6814,
      "step": 610
    },
    {
      "epoch": 0.40542749713912046,
      "grad_norm": 0.5636910200119019,
      "learning_rate": 0.00017302832244008715,
      "loss": 1.6235,
      "step": 620
    },
    {
      "epoch": 0.4119666503187837,
      "grad_norm": 0.6189414858818054,
      "learning_rate": 0.0001725925925925926,
      "loss": 1.6524,
      "step": 630
    },
    {
      "epoch": 0.41850580349844696,
      "grad_norm": 0.6055302023887634,
      "learning_rate": 0.00017215686274509807,
      "loss": 1.7722,
      "step": 640
    },
    {
      "epoch": 0.4250449566781102,
      "grad_norm": 0.5800638198852539,
      "learning_rate": 0.0001717211328976035,
      "loss": 1.613,
      "step": 650
    },
    {
      "epoch": 0.4315841098577734,
      "grad_norm": 0.5359666347503662,
      "learning_rate": 0.00017128540305010894,
      "loss": 1.6511,
      "step": 660
    },
    {
      "epoch": 0.43812326303743665,
      "grad_norm": 0.510686993598938,
      "learning_rate": 0.00017084967320261439,
      "loss": 1.5907,
      "step": 670
    },
    {
      "epoch": 0.4446624162170999,
      "grad_norm": 0.6094375252723694,
      "learning_rate": 0.00017041394335511983,
      "loss": 1.631,
      "step": 680
    },
    {
      "epoch": 0.45120156939676315,
      "grad_norm": 0.4880543351173401,
      "learning_rate": 0.00016997821350762528,
      "loss": 1.6235,
      "step": 690
    },
    {
      "epoch": 0.45774072257642634,
      "grad_norm": 0.6017512083053589,
      "learning_rate": 0.00016954248366013073,
      "loss": 1.6503,
      "step": 700
    },
    {
      "epoch": 0.45774072257642634,
      "eval_loss": 1.6215054988861084,
      "eval_runtime": 214.1266,
      "eval_samples_per_second": 6.351,
      "eval_steps_per_second": 1.588,
      "step": 700
    },
    {
      "epoch": 0.4642798757560896,
      "grad_norm": 0.52732914686203,
      "learning_rate": 0.00016910675381263618,
      "loss": 1.6167,
      "step": 710
    },
    {
      "epoch": 0.47081902893575284,
      "grad_norm": 0.599014163017273,
      "learning_rate": 0.00016867102396514162,
      "loss": 1.648,
      "step": 720
    },
    {
      "epoch": 0.47735818211541603,
      "grad_norm": 0.6181223392486572,
      "learning_rate": 0.00016823529411764707,
      "loss": 1.5541,
      "step": 730
    },
    {
      "epoch": 0.4838973352950793,
      "grad_norm": 0.5502867102622986,
      "learning_rate": 0.00016779956427015252,
      "loss": 1.6257,
      "step": 740
    },
    {
      "epoch": 0.4904364884747425,
      "grad_norm": 0.541590690612793,
      "learning_rate": 0.00016736383442265794,
      "loss": 1.6078,
      "step": 750
    },
    {
      "epoch": 0.4969756416544058,
      "grad_norm": 0.6020298004150391,
      "learning_rate": 0.00016692810457516341,
      "loss": 1.6076,
      "step": 760
    },
    {
      "epoch": 0.503514794834069,
      "grad_norm": 0.5160979628562927,
      "learning_rate": 0.00016649237472766886,
      "loss": 1.6206,
      "step": 770
    },
    {
      "epoch": 0.5100539480137323,
      "grad_norm": 0.5133918523788452,
      "learning_rate": 0.00016605664488017428,
      "loss": 1.6146,
      "step": 780
    },
    {
      "epoch": 0.5165931011933954,
      "grad_norm": 0.5984551310539246,
      "learning_rate": 0.00016562091503267973,
      "loss": 1.605,
      "step": 790
    },
    {
      "epoch": 0.5231322543730587,
      "grad_norm": 0.5790736079216003,
      "learning_rate": 0.0001651851851851852,
      "loss": 1.5975,
      "step": 800
    },
    {
      "epoch": 0.5231322543730587,
      "eval_loss": 1.6105530261993408,
      "eval_runtime": 216.9527,
      "eval_samples_per_second": 6.269,
      "eval_steps_per_second": 1.567,
      "step": 800
    },
    {
      "epoch": 0.5296714075527219,
      "grad_norm": 0.558170735836029,
      "learning_rate": 0.00016474945533769065,
      "loss": 1.6414,
      "step": 810
    },
    {
      "epoch": 0.5362105607323852,
      "grad_norm": 0.5168609023094177,
      "learning_rate": 0.00016431372549019607,
      "loss": 1.6196,
      "step": 820
    },
    {
      "epoch": 0.5427497139120484,
      "grad_norm": 0.5333762168884277,
      "learning_rate": 0.00016387799564270155,
      "loss": 1.5818,
      "step": 830
    },
    {
      "epoch": 0.5492888670917117,
      "grad_norm": 0.4931408762931824,
      "learning_rate": 0.000163442265795207,
      "loss": 1.6026,
      "step": 840
    },
    {
      "epoch": 0.5558280202713749,
      "grad_norm": 0.5769644379615784,
      "learning_rate": 0.00016300653594771242,
      "loss": 1.7284,
      "step": 850
    },
    {
      "epoch": 0.562367173451038,
      "grad_norm": 0.5904828906059265,
      "learning_rate": 0.00016257080610021786,
      "loss": 1.5978,
      "step": 860
    },
    {
      "epoch": 0.5689063266307013,
      "grad_norm": 0.610977292060852,
      "learning_rate": 0.00016213507625272334,
      "loss": 1.5596,
      "step": 870
    },
    {
      "epoch": 0.5754454798103645,
      "grad_norm": 0.6873355507850647,
      "learning_rate": 0.00016169934640522876,
      "loss": 1.5719,
      "step": 880
    },
    {
      "epoch": 0.5819846329900278,
      "grad_norm": 0.7610468864440918,
      "learning_rate": 0.0001612636165577342,
      "loss": 1.6444,
      "step": 890
    },
    {
      "epoch": 0.588523786169691,
      "grad_norm": 0.5393158793449402,
      "learning_rate": 0.00016082788671023965,
      "loss": 1.5739,
      "step": 900
    },
    {
      "epoch": 0.588523786169691,
      "eval_loss": 1.6006444692611694,
      "eval_runtime": 215.4879,
      "eval_samples_per_second": 6.311,
      "eval_steps_per_second": 1.578,
      "step": 900
    },
    {
      "epoch": 0.5950629393493543,
      "grad_norm": 0.6041072607040405,
      "learning_rate": 0.0001603921568627451,
      "loss": 1.6178,
      "step": 910
    },
    {
      "epoch": 0.6016020925290175,
      "grad_norm": 0.6023659706115723,
      "learning_rate": 0.00015995642701525055,
      "loss": 1.6913,
      "step": 920
    },
    {
      "epoch": 0.6081412457086808,
      "grad_norm": 0.6058598756790161,
      "learning_rate": 0.000159520697167756,
      "loss": 1.5645,
      "step": 930
    },
    {
      "epoch": 0.6146803988883439,
      "grad_norm": 0.556288480758667,
      "learning_rate": 0.00015908496732026145,
      "loss": 1.6624,
      "step": 940
    },
    {
      "epoch": 0.6212195520680072,
      "grad_norm": 0.665423572063446,
      "learning_rate": 0.0001586492374727669,
      "loss": 1.6302,
      "step": 950
    },
    {
      "epoch": 0.6277587052476704,
      "grad_norm": 0.5671553015708923,
      "learning_rate": 0.00015821350762527234,
      "loss": 1.6453,
      "step": 960
    },
    {
      "epoch": 0.6342978584273337,
      "grad_norm": 0.6914359927177429,
      "learning_rate": 0.0001577777777777778,
      "loss": 1.5534,
      "step": 970
    },
    {
      "epoch": 0.6408370116069969,
      "grad_norm": 0.6395360231399536,
      "learning_rate": 0.00015734204793028324,
      "loss": 1.6458,
      "step": 980
    },
    {
      "epoch": 0.6473761647866602,
      "grad_norm": 0.6171602010726929,
      "learning_rate": 0.00015690631808278868,
      "loss": 1.5613,
      "step": 990
    },
    {
      "epoch": 0.6539153179663234,
      "grad_norm": 0.6094607710838318,
      "learning_rate": 0.00015647058823529413,
      "loss": 1.6107,
      "step": 1000
    },
    {
      "epoch": 0.6539153179663234,
      "eval_loss": 1.592980980873108,
      "eval_runtime": 215.5939,
      "eval_samples_per_second": 6.308,
      "eval_steps_per_second": 1.577,
      "step": 1000
    },
    {
      "epoch": 0.6604544711459865,
      "grad_norm": 0.5408118963241577,
      "learning_rate": 0.00015603485838779955,
      "loss": 1.644,
      "step": 1010
    },
    {
      "epoch": 0.6669936243256498,
      "grad_norm": 0.7458732724189758,
      "learning_rate": 0.00015559912854030503,
      "loss": 1.6245,
      "step": 1020
    },
    {
      "epoch": 0.673532777505313,
      "grad_norm": 0.5530688762664795,
      "learning_rate": 0.00015516339869281047,
      "loss": 1.5689,
      "step": 1030
    },
    {
      "epoch": 0.6800719306849763,
      "grad_norm": 0.6456759572029114,
      "learning_rate": 0.00015472766884531592,
      "loss": 1.5646,
      "step": 1040
    },
    {
      "epoch": 0.6866110838646395,
      "grad_norm": 0.5792504549026489,
      "learning_rate": 0.00015429193899782134,
      "loss": 1.6024,
      "step": 1050
    },
    {
      "epoch": 0.6931502370443028,
      "grad_norm": 0.6265180706977844,
      "learning_rate": 0.00015385620915032682,
      "loss": 1.662,
      "step": 1060
    },
    {
      "epoch": 0.699689390223966,
      "grad_norm": 0.6539197564125061,
      "learning_rate": 0.00015342047930283226,
      "loss": 1.5564,
      "step": 1070
    },
    {
      "epoch": 0.7062285434036293,
      "grad_norm": 0.6584964394569397,
      "learning_rate": 0.00015298474945533769,
      "loss": 1.5261,
      "step": 1080
    },
    {
      "epoch": 0.7127676965832924,
      "grad_norm": 0.6851834654808044,
      "learning_rate": 0.00015254901960784313,
      "loss": 1.5768,
      "step": 1090
    },
    {
      "epoch": 0.7193068497629557,
      "grad_norm": 0.613867461681366,
      "learning_rate": 0.0001521132897603486,
      "loss": 1.5786,
      "step": 1100
    },
    {
      "epoch": 0.7193068497629557,
      "eval_loss": 1.5864918231964111,
      "eval_runtime": 215.8086,
      "eval_samples_per_second": 6.302,
      "eval_steps_per_second": 1.575,
      "step": 1100
    },
    {
      "epoch": 0.7258460029426189,
      "grad_norm": 0.6158707737922668,
      "learning_rate": 0.00015167755991285403,
      "loss": 1.6249,
      "step": 1110
    },
    {
      "epoch": 0.7323851561222822,
      "grad_norm": 0.5825197100639343,
      "learning_rate": 0.00015124183006535948,
      "loss": 1.6123,
      "step": 1120
    },
    {
      "epoch": 0.7389243093019454,
      "grad_norm": 0.6104593276977539,
      "learning_rate": 0.00015080610021786492,
      "loss": 1.6505,
      "step": 1130
    },
    {
      "epoch": 0.7454634624816087,
      "grad_norm": 0.6126224994659424,
      "learning_rate": 0.00015037037037037037,
      "loss": 1.5789,
      "step": 1140
    },
    {
      "epoch": 0.7520026156612719,
      "grad_norm": 0.5638230443000793,
      "learning_rate": 0.00014993464052287582,
      "loss": 1.5999,
      "step": 1150
    },
    {
      "epoch": 0.758541768840935,
      "grad_norm": 0.5619924664497375,
      "learning_rate": 0.00014949891067538127,
      "loss": 1.551,
      "step": 1160
    },
    {
      "epoch": 0.7650809220205983,
      "grad_norm": 0.5563178658485413,
      "learning_rate": 0.00014906318082788674,
      "loss": 1.5705,
      "step": 1170
    },
    {
      "epoch": 0.7716200752002615,
      "grad_norm": 0.5563811659812927,
      "learning_rate": 0.00014862745098039216,
      "loss": 1.6266,
      "step": 1180
    },
    {
      "epoch": 0.7781592283799248,
      "grad_norm": 0.5909349918365479,
      "learning_rate": 0.0001481917211328976,
      "loss": 1.6552,
      "step": 1190
    },
    {
      "epoch": 0.784698381559588,
      "grad_norm": 0.597557008266449,
      "learning_rate": 0.00014775599128540306,
      "loss": 1.5995,
      "step": 1200
    },
    {
      "epoch": 0.784698381559588,
      "eval_loss": 1.5785441398620605,
      "eval_runtime": 217.4459,
      "eval_samples_per_second": 6.254,
      "eval_steps_per_second": 1.564,
      "step": 1200
    },
    {
      "epoch": 0.7912375347392513,
      "grad_norm": 0.5513367652893066,
      "learning_rate": 0.0001473202614379085,
      "loss": 1.5703,
      "step": 1210
    },
    {
      "epoch": 0.7977766879189145,
      "grad_norm": 0.5846370458602905,
      "learning_rate": 0.00014688453159041395,
      "loss": 1.6431,
      "step": 1220
    },
    {
      "epoch": 0.8043158410985778,
      "grad_norm": 0.5523406863212585,
      "learning_rate": 0.0001464488017429194,
      "loss": 1.6383,
      "step": 1230
    },
    {
      "epoch": 0.8108549942782409,
      "grad_norm": 0.5895868539810181,
      "learning_rate": 0.00014601307189542485,
      "loss": 1.5814,
      "step": 1240
    },
    {
      "epoch": 0.8173941474579042,
      "grad_norm": 0.618156909942627,
      "learning_rate": 0.0001455773420479303,
      "loss": 1.5846,
      "step": 1250
    },
    {
      "epoch": 0.8239333006375674,
      "grad_norm": 0.6279346942901611,
      "learning_rate": 0.00014514161220043574,
      "loss": 1.5884,
      "step": 1260
    },
    {
      "epoch": 0.8304724538172307,
      "grad_norm": 0.5845045447349548,
      "learning_rate": 0.0001447058823529412,
      "loss": 1.5995,
      "step": 1270
    },
    {
      "epoch": 0.8370116069968939,
      "grad_norm": 0.6107996702194214,
      "learning_rate": 0.0001442701525054466,
      "loss": 1.5339,
      "step": 1280
    },
    {
      "epoch": 0.8435507601765572,
      "grad_norm": 0.6060726642608643,
      "learning_rate": 0.00014383442265795209,
      "loss": 1.561,
      "step": 1290
    },
    {
      "epoch": 0.8500899133562204,
      "grad_norm": 0.5947033166885376,
      "learning_rate": 0.00014339869281045753,
      "loss": 1.5528,
      "step": 1300
    },
    {
      "epoch": 0.8500899133562204,
      "eval_loss": 1.5742528438568115,
      "eval_runtime": 216.0054,
      "eval_samples_per_second": 6.296,
      "eval_steps_per_second": 1.574,
      "step": 1300
    },
    {
      "epoch": 0.8566290665358836,
      "grad_norm": 0.6131241917610168,
      "learning_rate": 0.00014296296296296295,
      "loss": 1.5504,
      "step": 1310
    },
    {
      "epoch": 0.8631682197155468,
      "grad_norm": 0.6079211235046387,
      "learning_rate": 0.0001425272331154684,
      "loss": 1.633,
      "step": 1320
    },
    {
      "epoch": 0.86970737289521,
      "grad_norm": 0.6534780859947205,
      "learning_rate": 0.00014209150326797388,
      "loss": 1.6332,
      "step": 1330
    },
    {
      "epoch": 0.8762465260748733,
      "grad_norm": 0.5677270293235779,
      "learning_rate": 0.0001416557734204793,
      "loss": 1.553,
      "step": 1340
    },
    {
      "epoch": 0.8827856792545365,
      "grad_norm": 0.597781240940094,
      "learning_rate": 0.00014122004357298475,
      "loss": 1.5857,
      "step": 1350
    },
    {
      "epoch": 0.8893248324341998,
      "grad_norm": 0.5568802952766418,
      "learning_rate": 0.00014078431372549022,
      "loss": 1.5794,
      "step": 1360
    },
    {
      "epoch": 0.895863985613863,
      "grad_norm": 0.6080300807952881,
      "learning_rate": 0.00014034858387799567,
      "loss": 1.6244,
      "step": 1370
    },
    {
      "epoch": 0.9024031387935263,
      "grad_norm": 0.6102612018585205,
      "learning_rate": 0.0001399128540305011,
      "loss": 1.6152,
      "step": 1380
    },
    {
      "epoch": 0.9089422919731894,
      "grad_norm": 0.6086609959602356,
      "learning_rate": 0.00013947712418300654,
      "loss": 1.6034,
      "step": 1390
    },
    {
      "epoch": 0.9154814451528527,
      "grad_norm": 0.5718315243721008,
      "learning_rate": 0.000139041394335512,
      "loss": 1.5665,
      "step": 1400
    },
    {
      "epoch": 0.9154814451528527,
      "eval_loss": 1.568448543548584,
      "eval_runtime": 217.2573,
      "eval_samples_per_second": 6.26,
      "eval_steps_per_second": 1.565,
      "step": 1400
    },
    {
      "epoch": 0.9220205983325159,
      "grad_norm": 0.6142221093177795,
      "learning_rate": 0.00013860566448801743,
      "loss": 1.5824,
      "step": 1410
    },
    {
      "epoch": 0.9285597515121792,
      "grad_norm": 0.6104479432106018,
      "learning_rate": 0.00013816993464052288,
      "loss": 1.5799,
      "step": 1420
    },
    {
      "epoch": 0.9350989046918424,
      "grad_norm": 0.6188782453536987,
      "learning_rate": 0.00013773420479302833,
      "loss": 1.5793,
      "step": 1430
    },
    {
      "epoch": 0.9416380578715057,
      "grad_norm": 0.6620565056800842,
      "learning_rate": 0.00013729847494553377,
      "loss": 1.5284,
      "step": 1440
    },
    {
      "epoch": 0.9481772110511689,
      "grad_norm": 0.7121399641036987,
      "learning_rate": 0.00013686274509803922,
      "loss": 1.5715,
      "step": 1450
    },
    {
      "epoch": 0.9547163642308321,
      "grad_norm": 0.568631112575531,
      "learning_rate": 0.00013642701525054467,
      "loss": 1.556,
      "step": 1460
    },
    {
      "epoch": 0.9612555174104953,
      "grad_norm": 0.5634791254997253,
      "learning_rate": 0.00013599128540305012,
      "loss": 1.6002,
      "step": 1470
    },
    {
      "epoch": 0.9677946705901586,
      "grad_norm": 0.6420175433158875,
      "learning_rate": 0.00013555555555555556,
      "loss": 1.591,
      "step": 1480
    },
    {
      "epoch": 0.9743338237698218,
      "grad_norm": 0.5890277624130249,
      "learning_rate": 0.000135119825708061,
      "loss": 1.6366,
      "step": 1490
    },
    {
      "epoch": 0.980872976949485,
      "grad_norm": 0.6771460771560669,
      "learning_rate": 0.00013468409586056646,
      "loss": 1.6021,
      "step": 1500
    },
    {
      "epoch": 0.980872976949485,
      "eval_loss": 1.5623639822006226,
      "eval_runtime": 215.0725,
      "eval_samples_per_second": 6.323,
      "eval_steps_per_second": 1.581,
      "step": 1500
    },
    {
      "epoch": 0.9874121301291483,
      "grad_norm": 0.6375719308853149,
      "learning_rate": 0.00013424836601307188,
      "loss": 1.5548,
      "step": 1510
    },
    {
      "epoch": 0.9939512833088116,
      "grad_norm": 0.6278295516967773,
      "learning_rate": 0.00013381263616557736,
      "loss": 1.6551,
      "step": 1520
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.2181743383407593,
      "learning_rate": 0.0001333769063180828,
      "loss": 1.5724,
      "step": 1530
    },
    {
      "epoch": 1.0065391531796632,
      "grad_norm": 0.5833552479743958,
      "learning_rate": 0.00013294117647058822,
      "loss": 1.4691,
      "step": 1540
    },
    {
      "epoch": 1.0130783063593265,
      "grad_norm": 0.5850432515144348,
      "learning_rate": 0.0001325054466230937,
      "loss": 1.6214,
      "step": 1550
    },
    {
      "epoch": 1.0196174595389897,
      "grad_norm": 0.6727794408798218,
      "learning_rate": 0.00013206971677559915,
      "loss": 1.5786,
      "step": 1560
    },
    {
      "epoch": 1.026156612718653,
      "grad_norm": 0.631633996963501,
      "learning_rate": 0.00013163398692810457,
      "loss": 1.4997,
      "step": 1570
    },
    {
      "epoch": 1.0326957658983162,
      "grad_norm": 0.6603133678436279,
      "learning_rate": 0.00013119825708061001,
      "loss": 1.5238,
      "step": 1580
    },
    {
      "epoch": 1.0392349190779795,
      "grad_norm": 0.6236830949783325,
      "learning_rate": 0.0001307625272331155,
      "loss": 1.5539,
      "step": 1590
    },
    {
      "epoch": 1.0457740722576427,
      "grad_norm": 0.6665980219841003,
      "learning_rate": 0.00013032679738562094,
      "loss": 1.5752,
      "step": 1600
    },
    {
      "epoch": 1.0457740722576427,
      "eval_loss": 1.5591633319854736,
      "eval_runtime": 222.3286,
      "eval_samples_per_second": 6.117,
      "eval_steps_per_second": 1.529,
      "step": 1600
    },
    {
      "epoch": 1.0523132254373058,
      "grad_norm": 0.577596127986908,
      "learning_rate": 0.00012989106753812636,
      "loss": 1.5471,
      "step": 1610
    },
    {
      "epoch": 1.058852378616969,
      "grad_norm": 0.6563194990158081,
      "learning_rate": 0.0001294553376906318,
      "loss": 1.567,
      "step": 1620
    },
    {
      "epoch": 1.0653915317966323,
      "grad_norm": 0.6860426068305969,
      "learning_rate": 0.00012901960784313728,
      "loss": 1.5509,
      "step": 1630
    },
    {
      "epoch": 1.0719306849762955,
      "grad_norm": 0.6470491886138916,
      "learning_rate": 0.0001285838779956427,
      "loss": 1.5532,
      "step": 1640
    },
    {
      "epoch": 1.0784698381559588,
      "grad_norm": 0.6074150800704956,
      "learning_rate": 0.00012814814814814815,
      "loss": 1.4886,
      "step": 1650
    },
    {
      "epoch": 1.085008991335622,
      "grad_norm": 0.6140276789665222,
      "learning_rate": 0.0001277124183006536,
      "loss": 1.5671,
      "step": 1660
    },
    {
      "epoch": 1.0915481445152853,
      "grad_norm": 0.5775508284568787,
      "learning_rate": 0.00012727668845315904,
      "loss": 1.5943,
      "step": 1670
    },
    {
      "epoch": 1.0980872976949485,
      "grad_norm": 0.58351069688797,
      "learning_rate": 0.0001268409586056645,
      "loss": 1.561,
      "step": 1680
    },
    {
      "epoch": 1.1046264508746118,
      "grad_norm": 0.5868995785713196,
      "learning_rate": 0.00012640522875816994,
      "loss": 1.522,
      "step": 1690
    },
    {
      "epoch": 1.111165604054275,
      "grad_norm": 0.6725491285324097,
      "learning_rate": 0.00012596949891067539,
      "loss": 1.5358,
      "step": 1700
    },
    {
      "epoch": 1.111165604054275,
      "eval_loss": 1.5548652410507202,
      "eval_runtime": 222.8828,
      "eval_samples_per_second": 6.102,
      "eval_steps_per_second": 1.525,
      "step": 1700
    },
    {
      "epoch": 1.1177047572339383,
      "grad_norm": 0.587973952293396,
      "learning_rate": 0.00012553376906318083,
      "loss": 1.4799,
      "step": 1710
    },
    {
      "epoch": 1.1242439104136015,
      "grad_norm": 0.6557928323745728,
      "learning_rate": 0.00012509803921568628,
      "loss": 1.5184,
      "step": 1720
    },
    {
      "epoch": 1.1307830635932647,
      "grad_norm": 0.6995096802711487,
      "learning_rate": 0.00012466230936819173,
      "loss": 1.5438,
      "step": 1730
    },
    {
      "epoch": 1.137322216772928,
      "grad_norm": 0.6829426884651184,
      "learning_rate": 0.00012422657952069718,
      "loss": 1.5755,
      "step": 1740
    },
    {
      "epoch": 1.143861369952591,
      "grad_norm": 0.5761020183563232,
      "learning_rate": 0.00012379084967320262,
      "loss": 1.4913,
      "step": 1750
    },
    {
      "epoch": 1.1504005231322543,
      "grad_norm": 0.6767775416374207,
      "learning_rate": 0.00012335511982570807,
      "loss": 1.4551,
      "step": 1760
    },
    {
      "epoch": 1.1569396763119175,
      "grad_norm": 0.6301105618476868,
      "learning_rate": 0.0001229193899782135,
      "loss": 1.5065,
      "step": 1770
    },
    {
      "epoch": 1.1634788294915808,
      "grad_norm": 0.673538327217102,
      "learning_rate": 0.00012248366013071897,
      "loss": 1.4559,
      "step": 1780
    },
    {
      "epoch": 1.170017982671244,
      "grad_norm": 0.5751718878746033,
      "learning_rate": 0.00012204793028322442,
      "loss": 1.5251,
      "step": 1790
    },
    {
      "epoch": 1.1765571358509073,
      "grad_norm": 0.708681046962738,
      "learning_rate": 0.00012161220043572985,
      "loss": 1.5051,
      "step": 1800
    },
    {
      "epoch": 1.1765571358509073,
      "eval_loss": 1.5512124300003052,
      "eval_runtime": 220.7587,
      "eval_samples_per_second": 6.161,
      "eval_steps_per_second": 1.54,
      "step": 1800
    },
    {
      "epoch": 1.1830962890305705,
      "grad_norm": 0.6105163097381592,
      "learning_rate": 0.0001211764705882353,
      "loss": 1.4854,
      "step": 1810
    },
    {
      "epoch": 1.1896354422102338,
      "grad_norm": 0.6672012805938721,
      "learning_rate": 0.00012074074074074076,
      "loss": 1.4593,
      "step": 1820
    },
    {
      "epoch": 1.196174595389897,
      "grad_norm": 0.6049960255622864,
      "learning_rate": 0.00012030501089324619,
      "loss": 1.5296,
      "step": 1830
    },
    {
      "epoch": 1.2027137485695603,
      "grad_norm": 0.6807366609573364,
      "learning_rate": 0.00011986928104575164,
      "loss": 1.5694,
      "step": 1840
    },
    {
      "epoch": 1.2092529017492235,
      "grad_norm": 0.6367543935775757,
      "learning_rate": 0.00011943355119825707,
      "loss": 1.5837,
      "step": 1850
    },
    {
      "epoch": 1.2157920549288868,
      "grad_norm": 0.5930379033088684,
      "learning_rate": 0.00011899782135076254,
      "loss": 1.5724,
      "step": 1860
    },
    {
      "epoch": 1.22233120810855,
      "grad_norm": 0.6165681481361389,
      "learning_rate": 0.00011856209150326798,
      "loss": 1.4689,
      "step": 1870
    },
    {
      "epoch": 1.2288703612882133,
      "grad_norm": 0.711956262588501,
      "learning_rate": 0.00011812636165577342,
      "loss": 1.574,
      "step": 1880
    },
    {
      "epoch": 1.2354095144678765,
      "grad_norm": 0.7241868376731873,
      "learning_rate": 0.00011769063180827886,
      "loss": 1.5355,
      "step": 1890
    },
    {
      "epoch": 1.2419486676475398,
      "grad_norm": 0.6616709232330322,
      "learning_rate": 0.00011725490196078433,
      "loss": 1.5387,
      "step": 1900
    },
    {
      "epoch": 1.2419486676475398,
      "eval_loss": 1.5488284826278687,
      "eval_runtime": 215.973,
      "eval_samples_per_second": 6.297,
      "eval_steps_per_second": 1.574,
      "step": 1900
    },
    {
      "epoch": 1.248487820827203,
      "grad_norm": 0.6138182282447815,
      "learning_rate": 0.00011681917211328976,
      "loss": 1.5095,
      "step": 1910
    },
    {
      "epoch": 1.2550269740068662,
      "grad_norm": 0.6724655032157898,
      "learning_rate": 0.00011638344226579521,
      "loss": 1.5567,
      "step": 1920
    },
    {
      "epoch": 1.2615661271865293,
      "grad_norm": 0.7158101797103882,
      "learning_rate": 0.00011594771241830067,
      "loss": 1.5437,
      "step": 1930
    },
    {
      "epoch": 1.2681052803661925,
      "grad_norm": 0.6774012446403503,
      "learning_rate": 0.0001155119825708061,
      "loss": 1.5139,
      "step": 1940
    },
    {
      "epoch": 1.2746444335458558,
      "grad_norm": 0.8049024343490601,
      "learning_rate": 0.00011507625272331155,
      "loss": 1.5041,
      "step": 1950
    },
    {
      "epoch": 1.281183586725519,
      "grad_norm": 0.7040684223175049,
      "learning_rate": 0.00011464052287581698,
      "loss": 1.5063,
      "step": 1960
    },
    {
      "epoch": 1.2877227399051823,
      "grad_norm": 0.6937931776046753,
      "learning_rate": 0.00011420479302832246,
      "loss": 1.5116,
      "step": 1970
    },
    {
      "epoch": 1.2942618930848455,
      "grad_norm": 0.6478717923164368,
      "learning_rate": 0.0001137690631808279,
      "loss": 1.6253,
      "step": 1980
    },
    {
      "epoch": 1.3008010462645088,
      "grad_norm": 0.5948330163955688,
      "learning_rate": 0.00011333333333333334,
      "loss": 1.533,
      "step": 1990
    },
    {
      "epoch": 1.307340199444172,
      "grad_norm": 0.6857873201370239,
      "learning_rate": 0.00011289760348583878,
      "loss": 1.5324,
      "step": 2000
    },
    {
      "epoch": 1.307340199444172,
      "eval_loss": 1.5440155267715454,
      "eval_runtime": 214.3943,
      "eval_samples_per_second": 6.343,
      "eval_steps_per_second": 1.586,
      "step": 2000
    },
    {
      "epoch": 1.3138793526238353,
      "grad_norm": 0.6599450707435608,
      "learning_rate": 0.00011246187363834424,
      "loss": 1.5139,
      "step": 2010
    },
    {
      "epoch": 1.3204185058034985,
      "grad_norm": 0.829403817653656,
      "learning_rate": 0.00011202614379084968,
      "loss": 1.5828,
      "step": 2020
    },
    {
      "epoch": 1.3269576589831618,
      "grad_norm": 0.5963929891586304,
      "learning_rate": 0.00011159041394335512,
      "loss": 1.5115,
      "step": 2030
    },
    {
      "epoch": 1.3334968121628248,
      "grad_norm": 0.6871862411499023,
      "learning_rate": 0.00011115468409586057,
      "loss": 1.4877,
      "step": 2040
    },
    {
      "epoch": 1.340035965342488,
      "grad_norm": 0.6595432162284851,
      "learning_rate": 0.00011071895424836603,
      "loss": 1.4828,
      "step": 2050
    },
    {
      "epoch": 1.3465751185221513,
      "grad_norm": 0.6655598878860474,
      "learning_rate": 0.00011028322440087146,
      "loss": 1.4555,
      "step": 2060
    },
    {
      "epoch": 1.3531142717018145,
      "grad_norm": 0.6068859100341797,
      "learning_rate": 0.00010984749455337691,
      "loss": 1.5066,
      "step": 2070
    },
    {
      "epoch": 1.3596534248814778,
      "grad_norm": 0.6100261807441711,
      "learning_rate": 0.00010941176470588237,
      "loss": 1.5254,
      "step": 2080
    },
    {
      "epoch": 1.366192578061141,
      "grad_norm": 0.730141282081604,
      "learning_rate": 0.0001089760348583878,
      "loss": 1.5484,
      "step": 2090
    },
    {
      "epoch": 1.3727317312408043,
      "grad_norm": 0.5599851608276367,
      "learning_rate": 0.00010854030501089325,
      "loss": 1.5256,
      "step": 2100
    },
    {
      "epoch": 1.3727317312408043,
      "eval_loss": 1.542738914489746,
      "eval_runtime": 210.2378,
      "eval_samples_per_second": 6.469,
      "eval_steps_per_second": 1.617,
      "step": 2100
    },
    {
      "epoch": 1.3792708844204675,
      "grad_norm": 0.7188719511032104,
      "learning_rate": 0.00010810457516339869,
      "loss": 1.5204,
      "step": 2110
    },
    {
      "epoch": 1.3858100376001308,
      "grad_norm": 0.594989001750946,
      "learning_rate": 0.00010766884531590416,
      "loss": 1.5198,
      "step": 2120
    },
    {
      "epoch": 1.392349190779794,
      "grad_norm": 0.7767077684402466,
      "learning_rate": 0.0001072331154684096,
      "loss": 1.4937,
      "step": 2130
    },
    {
      "epoch": 1.3988883439594573,
      "grad_norm": 0.6177573204040527,
      "learning_rate": 0.00010679738562091503,
      "loss": 1.5578,
      "step": 2140
    },
    {
      "epoch": 1.4054274971391205,
      "grad_norm": 0.6446627378463745,
      "learning_rate": 0.00010636165577342048,
      "loss": 1.4688,
      "step": 2150
    },
    {
      "epoch": 1.4119666503187838,
      "grad_norm": 0.6425418853759766,
      "learning_rate": 0.00010592592592592594,
      "loss": 1.4653,
      "step": 2160
    },
    {
      "epoch": 1.418505803498447,
      "grad_norm": 0.6663811206817627,
      "learning_rate": 0.00010549019607843139,
      "loss": 1.5175,
      "step": 2170
    },
    {
      "epoch": 1.4250449566781103,
      "grad_norm": 0.6050153374671936,
      "learning_rate": 0.00010505446623093682,
      "loss": 1.5527,
      "step": 2180
    },
    {
      "epoch": 1.4315841098577735,
      "grad_norm": 0.6904441714286804,
      "learning_rate": 0.00010461873638344227,
      "loss": 1.5527,
      "step": 2190
    },
    {
      "epoch": 1.4381232630374368,
      "grad_norm": 0.6381367444992065,
      "learning_rate": 0.00010418300653594773,
      "loss": 1.5221,
      "step": 2200
    },
    {
      "epoch": 1.4381232630374368,
      "eval_loss": 1.538297414779663,
      "eval_runtime": 321.3552,
      "eval_samples_per_second": 4.232,
      "eval_steps_per_second": 1.058,
      "step": 2200
    }
  ],
  "logging_steps": 10,
  "max_steps": 4590,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 100,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 5.448535487165645e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
